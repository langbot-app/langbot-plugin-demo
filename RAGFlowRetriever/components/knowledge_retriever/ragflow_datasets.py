# Auto generated by LangBot Plugin SDK.
# Please refer to https://docs.langbot.app/en/plugin/dev/tutor.html for more details.
from __future__ import annotations

from typing import Any
import httpx

from langbot_plugin.api.definition.components.knowledge_retriever.retriever import KnowledgeRetriever
from langbot_plugin.api.entities.builtin.provider.message import ContentElement
from langbot_plugin.api.entities.builtin.rag.context import RetrievalContext, RetrievalResultEntry


class RAGFlowDatasets(KnowledgeRetriever):

    async def retrieve(self, context: RetrievalContext) -> list[RetrievalResultEntry]:
        """Retrieve knowledge from RAGFlow datasets"""

        # Get configuration values
        api_base_url = self.config.get('api_base_url', 'http://localhost:9380')
        api_key = self.config.get('api_key')
        dataset_ids_str = self.config.get('dataset_ids', '')
        top_k = self.config.get('top_k', 1024)
        similarity_threshold = self.config.get('similarity_threshold', 0.2)
        vector_similarity_weight = self.config.get('vector_similarity_weight', 0.3)
        page_size = self.config.get('page_size', 30)

        if not api_key or not dataset_ids_str:
            self.logger.error("Missing required configuration: api_key or dataset_ids")
            return []

        # Parse dataset IDs from comma-separated string
        dataset_ids = [did.strip() for did in dataset_ids_str.split(',') if did.strip()]

        if not dataset_ids:
            self.logger.error("No valid dataset IDs provided")
            return []

        # Remove trailing slash from base URL if present
        api_base_url = api_base_url.rstrip('/')

        # Prepare the API request
        url = f"{api_base_url}/api/v1/retrieval"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "question": context.query,
            "dataset_ids": dataset_ids,
            "page": 1,
            "page_size": int(page_size),
            "similarity_threshold": float(similarity_threshold),
            "vector_similarity_weight": float(vector_similarity_weight),
            "top_k": int(top_k),
            "keyword": False,
            "highlight": False
        }

        try:
            # Make the API request
            async with httpx.AsyncClient() as client:
                response = await client.post(url, json=payload, headers=headers, timeout=30.0)
                response.raise_for_status()

                data = response.json()

                # Check for successful response
                if data.get('code') != 0:
                    self.logger.error(f"RAGFlow API returned error code: {data.get('code')}")
                    return []

                # Parse the response and convert to RetrievalResultEntry
                results = []
                chunks = data.get('data', {}).get('chunks', [])

                for chunk in chunks:
                    # RAGFlow uses 'similarity' for overall score
                    # It also provides term_similarity and vector_similarity separately
                    entry = RetrievalResultEntry(
                        content=ContentElement.from_text(chunk.get('content', '')),
                        distance=1.0 - float(chunk.get('similarity', 0.0)),
                        metadata={
                            'chunk_id': chunk.get('id', ''),
                            'document_id': chunk.get('document_id', ''),
                            'kb_id': chunk.get('kb_id', ''),
                            'document_keyword': chunk.get('document_keyword', ''),
                            'important_keywords': chunk.get('important_keywords', []),
                            'term_similarity': chunk.get('term_similarity', 0.0),
                            'vector_similarity': chunk.get('vector_similarity', 0.0),
                            'positions': chunk.get('positions', []),
                            'image_id': chunk.get('image_id'),
                        }
                    )
                    results.append(entry)

                self.logger.info(f"Retrieved {len(results)} chunks from RAGFlow datasets: {dataset_ids}")
                return results

        except httpx.HTTPStatusError as e:
            self.logger.error(f"HTTP error from RAGFlow API: {e.response.status_code} - {e.response.text}")
            return []
        except httpx.RequestError as e:
            self.logger.error(f"Request error when calling RAGFlow API: {str(e)}")
            return []
        except Exception as e:
            self.logger.error(f"Unexpected error during retrieval: {str(e)}")
            return []
